# 缓存相关

## redis和memcached的区别

​		相对于 Memcached，来说如果他断电了数

​			据也就没有了，不能像Redis一样支持数据的持久化，在这一点上Redis做的比他好，并且它包含了

​			Memcached的几乎所有的功能并且比他更加强大，作为Java来说Redis是一个不错的缓存数据库，

​			这只是Redis的一部分功能，还有更多的强大的功能，并且Memcached只支持json格式的字符串，	

​			但是Redis支持很多种数据类型，所以在现在的市场上Memcached已经逐渐被Redis取代了

​		不同点：

```
				1、支持的数据结构类型
						Memcache仅仅支持键值对，Redis支持List，Hash,Set.Zset等等
				2、数据持久化
						Memcache只支持内存，不提供持久化，数据无法恢复，Redis有Rdb，以及Aof的策略进行数据持久化
				3、过期策略
						Memcache在set时指定，Redis可以先设置后修改
```

## redis支持哪些数据结构

​		五种数据类型：

​						字符串（String）

​						哈希（hash）

​						字符串列表（list）

​						字符串集合（set）

​						有序字符串集合（zset       sorted set）

​		但是在Redis5.0中发布了新的数据类型

​			Stream data type 

## redis是单线程的么，所有的工作都是单线程么

​		Redis是单线程的，redis实际上是采用了线程封闭的观念，把任务封闭在一个线程，自然避免了线程安全问题，不过对于需要依赖多个redis操作的复合操作来说，依然需要锁，而且有可能是分布式锁。 所有的工作并不是单线程的，而是使用I/O的多路复用，

​		Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的 

​		那么什么是多路I/O的复用呢？		

​		多路指的是多个TCP连接，复用指一个或者多个线程进行处理，在Redis中是单线程的，简单的理解就是多个TCP连接进行数据写入的请求，通过一个单线程进行多路的IO写入，这个就是多路IO复用，但是I/O的多路复用也是有很多种模型的，常见的有select、poll、epoll。

​		而在Redis当中使用的epoll。

## redis如何存储一个String的

​		通过他的Key  Value的键值对进行存储。

## 用过 Redis 的哪些数据结构, 分别用在什么场景?

### String

```
		String类型他并不是只能存储String，也能用来存储Long，等等，他可以用来存储一些结构简单的数据，并且效率非常高，像日常的一些单个的值往里面存，例如用户的token，还有用户的信息。
```

### Hash

```
		Hash是一个字典类型，这个时候我们可以用它来存储一些需要频繁修改的对象，例如用户的积分（但一般也是在数据库中存储，Redis存储一般用来提高效率），那么我们需要对用户的积分进行改动，而且这种改动还比较频繁，那么我们可以使用Hash来进行存储这个用户对象，因为如果使用String的话他会全部的序列化出来再存储进去，这样造成的大量IO比较消耗性能。
```

### List

```
		List是一个列表，他其实是一个链表，但是更多的使用时是将他当做一个消息队列来使用，因为他可以push和pop这和Java中的Queue队列一样，我们可以使用它来做一个消息队列。
```

### Set

```
		Set是一个集合，他和Java中的Set也是一样的无序的不唯一的值，如果使用的话场景还是比较多的，例如向的好友列表，还有关注的用户，和粉丝，以及还能用来统计访问用户，比如统计某一天的用户访问量，和访问过的用户。			
```

### ZSet

```
		ZSet是一个有序的集合，他可以用来存储集合并且做一个排序，那么我们可以使用他来进行一个点赞的操作，应为他去重并且有序，通常用于一些需要频繁操作的数据，并且需要实时排名的数据我们可以考虑使用ZSet。
```

​		这几个数据类型更多的是结合实际的业务需求来进行使用的

## 缓存击穿

​		首先我们需要了解什么是缓存击穿。

​		缓存击穿是指我们在访问数据的时候加上了缓存，例如商城首页的热点数据，又或者是微博热点新闻，或者其他热点数据，我们对他进行了缓存，因为这部分的数据访问量较大，我们不能直接查询数据库，而是先从数据库中查询，然后缓存到缓存中间件或者本地中，当然这个缓存是有一个时间的，如果说这个时候刚好有很多用户来访问我们的热点数据，然后缓存刚好失效，那么这个时候就会有非常多的并发到我们的MySQL中，MySQL可能会由于请求过多崩溃或者其他异常导致不可用，这种情况下我们称之为缓存击穿。

​		简单概述：例如我们将某个商品ID缓存到Redis中，但是某一个时间点这个缓存失效了，这个时候就有大量的这个商品的请求，来查询MySQL，导致MySQL扛不住。

​		那么如何解决这个问题呢？

​		我们可以采用加锁的方式进行访问，例如多个线程只能有一个能够获取到锁对象，他去查询后，再将数据放回Redis，其他线程获取到锁之后先去查询Redis，因为被其他线程设置了，所以现在Redis是有缓存的，这样就避免了大量请求到数据库。

​		加锁：

```java
				1、synchronized							 //	单体项目中使用
				2、ReentrantLock							 //	单体项目中使用
				3、Redis锁										// 分布式项目使用
				4、Zookeeper锁								// 分布式项目使用
```

## 缓存穿透

​		缓存穿透是指我们例如商品有3000个，ID为1-3000，那么这个时候有人恶意的去攻击我们的网站，它采用-1的ID，或者是采用大于3000的ID去请求数据，那么这个时候缓存中是始终查询不到的，如果他持续的采用一些恶意的ID进行攻击，那么我们的数据库压力就会非常大。

​		简单概述：采用大部分不存在的数据进行请求，绕过缓存，造成大量数据请求数据库，导致数据库压力过大或者崩溃。

​		那么我们如何解决这个问题呢？

​		我们可以将这一步商品的ID或者说这个缓存标识符，给存储起来，也就是有效的缓存标识符，例如1-3000，我们将它存储到某一个地方，每次查询缓存前我们先查询他是不是一个有效的缓存标识符。

​		缓存标识：

```java
				1、ConcurrentHashMap或者CopyOnWriteArraySet等并发容器
          
        		我们将所有的商品ID放到并发容器中，每次查询前先访问是否存在这个ID，不存在直接返回NULL，防止缓存击穿。
          	缺点：分布式情况实现不方便，需要结合发布订阅或者其他分布式同步ID（后续新增的商品ID）
          
				2、Redis布隆过滤器
          
          	将所有的商品ID都存放到布隆过滤器当中，每次查询缓存时先走一下布隆过滤器，如果不存在那么直接返回NULL。
```

## 缓存雪崩

​		缓存雪崩是指我们在某一个时间中，大量的缓存失效，例如1-3000这3000个商品，有2000多个缓存在同一时间失效了，那么我们就需要查询两千个商品，以及争抢锁资源，并且随着大量用户的请求，引起缓存的雪崩。

​		简单概述：同一时间点多个缓存失效，导致大量请求访问数据库，引起缓存雪崩

​		那么我们如何解决这个方案呢?

​		我们就只能在设置缓存的超时时间时，动态随机的设置超时时间，或者设置不规律的超时时间，让我们的缓存不会大量的在同一个时间点失效。

## 缓存预热

​		首选我们需要了解什么是缓存预热？

​		缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。

​		这样就避免了上线后大量的查询数据库，还有写缓存的操作，避免大量并发请求同事访问数据库。

​		没有使用预热的情况下

```sh
1、项目上线
2、用户查询
3、查询数据库
4、存入缓存
```

​		使用缓存预热的情况下

```sh
1、查询数据库
2、存入缓存
3、项目上线
4、查询缓存
```

​		因为我们自己提前或者在启动中就将缓存进行预热，这样对于查库的请求我们是可控的，否则上线后大量的用户请求打到数据库中，如果说我们还有锁机制还有其他的业务，这样对于性能以及并发量的控制都会高出很多。

​		缓存预热的方案有很多种

```sh
1、自己编写一个预热程序页面，上线之前手动指定预加载的缓存
2、项目启动的时候指定将那些数据预热到缓存中
3、定时将数据进行缓存（可能会引起其他问题）
```

## 缓存降级

​		当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。

​		系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级，例如某一个非核心业务，大量的请求导致并发过高或者其他情况导致无法使用，但是我们不能让这个请求直接打到数据库中，不然的话这个时候又有非常多的请求导致数据库的压力过大，引起缓存和数据库都崩溃，我们认为这一部分数据非核心，一旦缓存出现问题了，我们对他进行降级。

​		解决方案：

​				对于非核心业务中出现了缓存异常或者其他问题，将请求拦截在数据库之外进行处理。

```sh
# 注意这里指非核心业务，核心业务如支付，交易，或者其他涉及重要的功能不允许缓存降级
1、查询数据
2、缓存异常
3、将请求拦截，不请求数据库，返回一个空，或者降级状态码
```

​				并且针对于这种服务降级，我们的实现方式也有所区别，自动降级和手动降级

```sh
1、自动降级
		代码中写死降级规则
2、手动降级
		将降级规则动态，一旦出现问题手动调用，可以保留降级接口进行调用，自己编一个web端的降级程序，或者使用分布式配置中心动态刷新规则
```

## redis持久化策略

### RDB

​		RDB的存储方式：在指定的时间间隔内将内存中的数据集快照写入磁盘，也
​				就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里

​		Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入
​		到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换
​		上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，
​		这就确保了极高的性能如果需要进行大规模数据的恢复，且对于数据
​		恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。
​		RDB的缺点是最后一次持久化后的数据可能丢失

​		rdb的保存的文件： 在redis.conf中配置文件名称，默认为dump.rdb

​		![](img/drb.png)

​		下面就是他的持久化的文件存储的路径

​		RDB持久化的保存策略

​		这是他的保存策略，如果60秒内发生了10000次数据操作则进行一次存储，

​		如果300秒发生了10次则会存入一次。如果900秒内发生了一次操作那么900秒后

​		就会备份一次，

​		![](img/%E4%BF%9D%E5%AD%98%E7%AD%96%E7%95%A5rdb.png)

​		stop-writes-on-bgsave-error yes
​		当Redis无法写入磁盘的话，直接关掉Redis的写操作

​		rdbcompression yes
​		进行rdb保存时，将文件压缩

​		rdbchecksum yes
​		在存储快照后，还可以让Redis使用CRC64算法来进行数
​		据校验，但是这样做会增加大约10%的性能消耗，如果希
​		望获取到最大的性能提升，可以关闭此功能

​	rdb的备份

​					先通过config get dir 查询rdb文件的目录
​					将*.rdb的文件拷贝到别的地方

​			 	rdb的恢复

​			 		先把备份的文件拷贝到工作目录下
​		 			关闭Redis
​		 			启动Redis, 备份数据会直接加载

​				注：清先看清楚配置文件的RDB的文件名和路径

​	优点：

​					 节省磁盘空间
 					 恢复速度快

​	rdb的缺点

​					虽然Redis在fork时使用了写时拷贝技术,

​					但是如果数据庞大时还是比较消耗性能



​					在备份周期在一定间隔时间做一次备份，所以如果
​					Redis意外down掉的话，就会丢失最后一次快照后的所有修改	

### AOF

​	 AOF默认不开启，需要手动在配置文件中配置

​			 可以在redis.conf中配置文件名称，默认为 appendonly.aof

​			![](img/AOF.png)

​		这分别是是否开启。默认是关闭的而RDB默认是开启的，他的路径和RDB是一样的

​		下面这个就是文件名了

​		那么如果RDB好AOF同时启动的话他会执行哪个呢？

​			AOF的备份机制和性能虽然和RDB不同, 但是备份和
​			恢复的操作同RDB一样，都是拷贝备份文件，需要
​			恢复时再拷贝到Redis工作目录下，启动系统即加载

​			**AOF和RDB同时开启，系统默认取AOF的数据**

​		持久化AOF

​			 AOF文件的保存路径，同RDB的路径一致

​			 如遇到AOF文件损坏，可通过
​				redis-check-aof --fix appendonly.aof 进行恢复

​		AOF优点：

​				恢复数据全，不会丢失数据

​		缺点：

​				占用磁盘空间较大，并且恢复没有RDB快，并且影响性能

- 如果只配置AOF，重启时加载AOF文件恢复数据；
- 如果同时配置了RBD和AOF，启动是只加载AOF文件恢复数据;
- 如果只配置RBD，启动时将加载dump文件恢复数据。

## Redis数据过期策略

​		我们知道Redis是有一个缓存的超时时间的，那么这个缓存的超时时间一到了时间就会直接删除吗？

​		答案是否定的，例如我们给一个key设置过期时间10秒，那么10秒钟后，在Redis中他没有被立即的给删除掉，在Redis中有两种策略淘汰过期的数据，分别是如下：

- ​						定期删除

```sh
# Redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定期遍历这个字典来删除到期的key。
# Redis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。
		1.从过期字典中随机 20 个 key；
		2.删除这 20 个 key 中已经过期的 key；
		3.如果过期的 key 比率超过 1/4，那就重复步骤 1
# Redis默认是每隔 100ms就随机抽取一些设置了过期时间的key，随机抽取一部分设置过期时间的Key可以减少Redis的压力，如果一下子扫描出上万个过期key，那么会导致Redis的负载过高引起性能降低，所以每间隔一段时间将一部分的过期Key进行淘汰，那么剩下的过期数据怎么删除呢？答案就是下面的惰性删除。
```

- ​						惰性删除

```sh
# 所谓惰性策略就是在客户端访问这个key的时候，redis对key的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。
# 由于定期删除会导致还有很多过期的数据没有删除，那么这部分数据我们怎么处理呢，就是在查询的时候懒删除，我们都知道懒加载=获取的时候加载，懒删除则对应=获取的时候删除。
```

## Redis内存淘汰策略

​		上面有了数据过期策略这个数据淘汰策略又是什么意思呢？

​		有了以上过期策略的说明后，就很容易理解为什么需要淘汰策略了，因为不管是定期采样删除还是惰性删除都不是一种完全精准的删除，就还是会存在key没有被删除掉的场景，所以就需要内存淘汰策略进行补充，预留出足够的内存空间，防止突然的大量缓存导致内存急剧增加。

​		Redis的内存淘汰策略如下：

```sh
1. noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键
2. allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键
3. volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键
4. allkeys-random：加入键的时候如果过限，从所有key随机删除
5. volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐
6. volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键
7. volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键
8. allkeys-lfu：从所有键中驱逐使用频率最少的键
```

​		在大部分的情况下推荐使用lru策略进行内存淘汰。

​		Redis中的LRU与常规的LRU实现并不相同，常规LRU会准确的淘汰掉队头的元素，但是Redis的LRU并不维护队列，只是根据配置的策略要么从所有的key中随机选择N个（N可以配置）要么从所有的设置了过期时间的key中选出N个键，然后再从这N个键中选出最久没有使用的一个key进行淘汰。

​		为什么要使用LRU？

​		1、性能问题，由于近似LRU算法只是最多随机采样N个key并对其进行排序，如果精准需要对所有key进行排序，这样近似LRU性能更高

​		2、内存占用问题，redis对内存要求很高，会尽量降低内存使用率，如果是抽样排序可以有效降低内存的占用

​		3、实际效果基本相等，如果请求符合长尾法则，那么真实LRU与Redis LRU之间表现基本无差异

​		4、在近似情况下提供可自配置的取样率来提升精准度，例如通过 CONFIG SET maxmemory-samples <count> 指令可以设置取样数，取样数越高越精准，如果你的CPU和内存有足够，可以提高取样数看命中率来探测最佳的采样比例。

## 知道动态字符串sds么？

​		动态字符串（simple dynamic string）

​		首先我们需要了解什么是sds动态字符串

​		我们知道Redis是采用C语言进行编写的，而所有的Key键都是字符串String类型，以及我们的很多的Value也会存储字符串，那么我们就要首先了解C语言的字符串了。

​		C语言中是没有String这个字符串类型的，而是采用的一个char数组，然后以\0作为一个结束符

```java
		// C语言中的字符串
		char *str;
    str = "redis";
		printf("%s",str);

		// 但是实际上这个str在转成String字符串的时候底层的char数组被转了,后面会多出一个/0的字符串结束符
		char str[5] = {'r','e','d','i','s','\0'};
```

​		那么我们在获取字符串的长度的时候，我们就会发现一个问题，我们需要遍历这个char数组，获取长度的时间复杂度是O(N)。

​		并且我们还会发现一个问题，我们存储二进制的时候，如果说二进制流中出现\0的时候，就会出现问题。

​		使用C字符串数组有以下问题

```properties
			1: 字符串数组的长度都是固定的，并且我们追加或者修改字符串数组相当于都是在重新创建内存空间，损耗内存
			2: 获取字符串长度时需要遍历字符串数组，时间复杂度较高，大量查询长度，会引起性能问题
			3: 存储二进制数据时，例如文件等等我们使用\0判断是否结尾，会导致二进制数据存储、查询长度、获取数据时引发的一系列问题
```

​		总体上来说则使用C语言转换后的String并不适合Redis用来存储，那么针对字符串的Key我们怎么去解决呢？

​		答案就是：动态字符串（simple dynamic string）SDS

​				那么SDS能帮助我们解决什么问题呢？，如下 : 

```properties
			1: SDS在字符串发生扩容的时候直接使用空闲的空间进行扩容，不需要重新分配数组对象，从而解决扩容问题
			2: 在SDS的内部定义了字符串的长度，使用时可以直接获取,将时间复杂度从O(n)变成了O(1)提高了长度查询效率
			3: SDS的空间预分配是惰性释放内存的，从而减少分配内存的次数
			4: SDS中存储了字符串的长度信息，我们可以直接根据起始位置，找到长度，获取数据，从而避免了二进制所导致问题
```

​		下面是SDS所存储的数据（老版本SDS >= 3.0）：

```c
struct sdshr{
  int len;  // 用于记录已使用数组长度，存储的字符串数据在buffer数组中的长度
  int free; // 用于记录数组剩余空间，用于追加时扩容是否需要扩容buffer
  char buf[];// 用于创建内存空间，以及存储的数据字符串buff数组
}
```

​		但其实这个buffer数组也是采用的\0进行存储的，那么为什么还要加上这个\0呢，答案就是为了兼容某些C的类库，所以还是需要\0进行结尾。

​		SDS空间分配策略：

- ​		**预留空间**

```java
		// 预留空间，是如何预留的呢？
					我们举例示范，例如 我们新建了一个字符串"redis",
          
					现在Buffer的长度是20
          char buf[20] = {'r','e','d','i','s','\0',.....空};

          那么此时的SDS如下
					struct sdshr{
            int len = 5;
            int free = 14;
            char buf[] = {'r','e','d','i','s','\0',.....空};
          }

					我们现在需要给他追加5.0.3这个字符串
          append("5.0.3");
					如果是采用来的字符串数组那么,则是
          char str[] = {'r','e','d','i','s','\0'};
					我们还需要将两个字符串的长度进行计算，然后创建一个新的字符串数组，再把值给添加进去
					而使用SDS我们就可以直接根据len找到数组的位置然后进行插入，也不需要创建新的数组对象
            															len
          																 |
            															 v
          char buf[] = {'r','e','d','i','s','\0',.....空};
```

- ​		**惰性空间释放**

```java
		// 惰性空间释放，是如何惰性空间释放的呢？
					还是以上面的示例
          
          我们将redis修改为key
          那么这个时候
          struct sdshr{
            int len = 3;
            int free = 16;
            char buf[] = {'k','e','y','\0',.....空};
          }

					我们可以看到buffer数组的长度还是没有变，我们下一次再插入一个redis5.0.3的时候是不会再创建内存空间的。
          这个时候我们数组长度还是20，那么再次修改的话我们的buffer数组不需要重新创建内存空间了。
          		缺点：
            			如果字符串占用较小的话只会修改free，占用内存空间，不立即释放
            			但是Redis作为一个内存缓存中间件来说的话，只要性能高，是可以牺牲一部分内存的
```

​		新版本的SDS,在SDS >= 4.0的版本源码如下：[点击进入](https://github.com/redis/redis/blob/unstable/src/sds.h)

```c
/* 注意： sdshdr5 从未使用过， 我们只是直接访问标志字节.
 * 但是，这里记录类型 5 SDS 字符串的布局. */
struct __attribute__ ((__packed__)) sdshdr5 {
    unsigned char flags; /*3 lsb 的类型，和 5 msb 的字符串长度 */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr8 {
    uint8_t len; /* 已经使用的长度 */
    uint8_t alloc; /* 排除掉Header以及null之后的可分配空间 */
    unsigned char flags; /* 3 lsb类型，5个未使用位 */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr16 {
    uint16_t len; /* used */
    uint16_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr32 {
    uint32_t len; /* used */
    uint32_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
struct __attribute__ ((__packed__)) sdshdr64 {
    uint64_t len; /* used */
    uint64_t alloc; /* excluding the header and null terminator */
    unsigned char flags; /* 3 lsb of type, 5 unused bits */
    char buf[];
};
```



## 集群主节点挂掉了怎么办

​		在Redis的Cluster集群模式下，我们以3主3从为示例，那么当其中的一个分片的Master宕掉了之后，那么Redis集群将会进行选举，选举条件为，存活Master节点  > 总Master节点 / 2。

​		还是三主三从为示例：

​				挂掉一台Master条件为：2 > 3 / 2 = true

​				挂掉两台Master条件为：1 > 3 / 2 = false

​		所以如果挂掉了两台Master之后，这两个Master的分片就无法使用了（注意：不是整个集群不可用）。

​		所以当集群中的某一个Master挂掉以后则会进行选举，当选举条件符合时，其他Master则会选举出新的从节点为Master，等原来的Master上线以后则降为Slave从节点。

## 集群脑裂问题

​		首先我们需要了解什么是脑裂问题，我们以1主2从一哨兵举例。

​		由于网络等原因出现分区，导致原来的Master没有挂，但是哨兵访问不到Master了，这个时候他认为Master挂掉了，从下面的从节点选举出新的Master节点，那么这个时候因为我们原来的Master没有挂，还有数据持续的往里面写入，这个时候旧Master写入了很多的数据了，现在网络突然又好了，导致原来的旧Master降级为从节点，再从新的从节点同步数据，这个时候就导致我们写的数据丢失的问题，也就是所谓的脑裂。

​		那么如何解决这个问题呢？

​		其实和我们的Elasticsearch差不多，但是Es是设置Master节点数，而Redis是设置从节点数。

​		我们可以修改Redis的配置文件防止脑裂问题

```java
　　　　（旧版本）
　　　　　　min-slaves-to-write 1			 // 如果存活的Slave小于1就不写入数据
　　　　　　min-slaves-max-lag 10			 // 主从复制的延迟不能超过的秒数
　　　　（新版本 >= 5.0）
　　　　　　min-replicas-to-write 1		 // 如果存活的Slave小于1就不写入数据
　　　　　　min-replicas-max-lag 10		 // 主从复制的延迟不能超过的秒数
```

## 你们用了redis，redis的底层数据结构了解多少？

​		简单动态字符串				官方源码：[点击进入](https://github.com/redis/redis/blob/unstable/src/sds.h)

​		链表									

​		字典									官方源码：[点击进入](https://github.com/redis/redis/blob/unstable/src/dict.h)

​		跳跃表							

​		整数集合

​		压缩列表

## Redis的数据是如何存储的？

​		**字典**是Redis最基础的数据结构，一个字典即一个DB，Redis支持多DB，例如，16个数据库就对应16个字典，

## Redis如果出现Key的哈希碰撞怎么办？

​		**Redis字典采用Hash表实现**，针对碰撞问题，采用的方法为“链地址法”，也就是链表+引用，例如某两个Key的Hash都一样，例如都是3，那么这个3存储的不是K和V，而是一个Key的引用，当发生冲突了的时候我们找到3，然后根据3找到这个饮用，如果这个Key对应，那么久取出他的值，如果不是这个Key，我们找到他的next，他指向下一个节点，我们再找到这个下一个节点他也同样有一个next指针，这样就解决了Hash碰撞的问题。

​		点击查看Redis字典源码：[点击进入](https://github.com/redis/redis/blob/unstable/src/dict.h)

​		字典Entry元素的定义如下

```c
typedef struct dictEntry {
  	// Key
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v; // Value
  	// next指针指向下一个节点
    struct dictEntry *next;
} dictEntry;
```

​		那么如果产生大量的Hash碰撞的话就会将这个Hash表退化成链表，这种情况我们怎么解决呢？Redis的方案是“双buffer”，正常流程使用一个buffer，当发现碰撞剧烈（判断依据为当前槽位数和Key数的对比），分配一个更大的buffer，然后逐步将数据从老的buffer迁移到新的buffer。

​		如下是C源码中对于

```c
dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)
{
    long index;
    dictEntry *entry;
    dictht *ht;

    if (dictIsRehashing(d)) _dictRehashStep(d);

    /* Get the index of the new element, or -1 if
     * the element already exists. */
    if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)
        return NULL;

    /* Allocate the memory and store the new entry.
     * Insert the element in top, with the assumption that in a database
     * system it is more likely that recently added entries are accessed
     * more frequently. */
    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];
    entry = zmalloc(sizeof(*entry));
    entry->next = ht->table[index];
    ht->table[index] = entry;
    ht->used++;

    /* Set the hash entry fields. */
    dictSetKey(d, entry, key);
    return entry;
}
```

​		也就是我们的扩容。

## 一个key值如何在redis集群中找到存储在哪里

​		一个 Redis 集群包含 16384 个插槽（hash slot）， 数据库中的每个键都属于这 16384 个插槽的其中一个， 集群使用公式 CRC16(key)% 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。 集群中的每个节点负责处理一部分插槽。 举个例子， 如果一个集群可以有主节点， 其中：
​				节点 A 负责处理 0 号至 5500 号插槽。
​				节点 B 负责处理 5501 号至 11000 号插槽。
​				节点 C 负责处理 11001 号至 16383 号插槽。

​		那么redis如果有3个节点，就会根据他的key进行计算key的CRC16的值然后来对16384 进行取模的操作

​		也就是（Key 计算后的CRC16    %     16384），然后再计算取模后的值在哪一个节点中，例如取模后是3000，那么他就会找到3000的这个槽，3000的这个槽是在A节点（1-5500）（假设为3个节点），那么他就会在第一个节点进行存储，如果查找的话也会去第一个节点进行查询。

## redis的单线程特性有什么优缺点？

优点：	

- ​			代码更清晰，处理逻辑更简单
- ​			不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
- ​			不存在多进程或者多线程导致的切换而消耗CPU

缺点：

- ​			无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善；

## Redis分布式锁以及注意事项

​		在使用Redis的锁的时候我们有非常多的注意事项，因为很有可能由于我们加锁的问题所引起的系统故障，主要的注意事项如下（大部分需要注意的事项，不是所有）：

​		1、setnx和expire的非原子性

​				在我们的业务场景中使用分布式锁，我们通常来说会去setnx来确定这个key是否存在，然后去设置他的超时时间，防止锁一直存在导致其他锁对象无法获取锁，但是这样是有问题的：

```sh
setnx
# 保存
不执行expire
```

​				那么我们刚刚setnx成功设置了锁，但是我们在要进行设置时间的时候抛出了异常，导致无法添加超时时间，其他的锁对象尝试获取锁一直获取不到导致程序线程请求累计，引起系统故障。

​				解决方案：

```sh
# 我们需要将设置值以及设置超时时间放到一起
# 在Redis2.6.12以上版本我们可以直接使用set将setnx和expire同时设置了如下所示
首先我们设置 一个key为lock的键然后他的值为1，然后超时时间两秒，设置类型为NX，那么这个相当于将setnx和expire一起设置了，这是一个原子性的操作
set lock 1 ex 2 NX
# 对于相应的API中，SpringDataRedis2.0以后也提供了相应的API去支持
```

​		2、解锁超时误解锁误删问题

​				那么在我们的设置锁的时候打个比方，我们有三个线程去获取锁，第一个线程去拿到锁，他将这个锁的超时时间设置成了2秒，那么我第二个线程进来没有获取到锁，进行等待，第一个锁还在执行中，2秒了他没有释放锁，但是这个锁过期了，我现在第二个锁获取到了这个锁，突然在这个时候，第一个锁执行完了，他来解锁了，实际上是我们的第二个锁的锁，第一个锁执行完后会直接将锁删除掉，那么第三个锁就开始执行了，这个时候我们的第二个锁和第三个锁是一起执行的，这样就导致了锁不住，以及锁误删的问题。

```sh
# 假设3个锁
		1、锁1获取锁执行程序
		2、锁1超时时间为2秒，但是2秒之后还没有执行完，这个锁已经超时了
		3、锁2获取锁，由于锁1超时所以可以拿到锁对象
		4、锁2拿到了锁对象，但是锁1执行完了代码，现在锁1要解锁了，把锁删掉了
		5、锁3笑咪咪的拿到了锁对象，此时锁2还在执行，这样就造成了锁1和锁2在同时执行，锁2和锁3也是同时执行的
```

​				解决方案：我们在set的时候将值设置为任务Id或者其他的唯一表示，在解锁的时候我们将设置的值和我们的id进行比较，如果这个锁是我们的我们进行解锁；

​				建议使用Lua脚本进行解锁，如果在代码中先Get然后判断值删除锁，有可能出现get的时候锁失效，然后还是误删的问题。

​				这里我们使用Lua脚本来进行删除，首先我们先获取这个KEY，然后根据这个KEY的值和传入的值进行比较，如何一样那么我们则删除原来的key，如果不一样则直接返回0即可。

​			首选我们先添加一个Key值为test

```sh
set test "test"
```

​			然后我们执行下面的代码，第一次执行我们会发现我们删除了，在执行一次则返回0

```sh
eval "if redis.call('get',KEYS[1]) == ARGV[1] then
        return redis.call('del',KEYS[1])
else
        return 0
end" 1 test "test"
```

​			3、master宕机丢锁问题

​					假设我们现在有两个线程去获取这个锁对象，我们假设他是锁1和锁2，那么首先我们进行模拟操作，锁1获取锁对象，在锁1获取到了锁对象之后，突然Master节点宕机，此时切换到丛节点，但是锁1的锁对象数据没有及时的同步到我们的锁2，那么这个时候锁1还在执行，锁2又来尝试获取锁对象，在这个时候由于从节点没有同步到Master的数据，那么锁2尝试从丛节点获取锁对象，这个时候是能够获取到的，那么就相当于这个时间我们的锁1和锁2都获取到了锁对象，这样就造成了锁不住，这也就是Master宕机丢锁的问题。

​					下面是执行的流程：

```sh
# 假设锁1和锁2，以及master和slave：
		1、首先锁1尝试获取锁对象，成功获得锁对象
		2、slave还没有从master同步数据，此时master挂掉了
		3、这个锁对象无法从master获取锁，切换到从节点
		4、锁2尝试获取锁对象，由于master宕机从节点无法同步到锁数据，锁2也成功获得锁对象
		5、引起锁问题，例如第二小节的锁误删问题，锁1执行完进行删锁，导致后面连续的锁对象混乱问题
```

​					解决方案：	

```
1、参考考虑下方的RedLock红锁机制进行实现，防止master宕机导致丢锁
2、使用其他的分布式锁方案进行解决，如Zookeeper或者MySQL（不推荐，Zk和MySQL的性能相比于Redis还是有一定的差距）
```

​		目前比较主流的分布式锁还是采用Redisson，帮助我们实现的Redis分布式锁功能较为完全以及强大。

## RedLock红锁

​			首先，我们需要知道什么是RedLock红锁，由于在我们分布式场景下经常使用分布式锁，Redis作者antirez基于分布式环境下提出了一种更高级的分布式锁的实现方式。

​			为什么需要使用RedLock算法，因为我们在单Redis实例实现分布式锁的时候如果写入锁到Master，在这个过程中Master挂掉了，然后

​			RedLock概念：假设我们具有多个Redis节点，

## 项目中有用到过布隆过滤器么？在哪些场景使用的

​			首先我们需要先了解什么是布隆过滤器，布隆过滤器（Bloom Filter）是由Howard Bloom在1970年提出的一种比较巧妙的概率型数据结构，它可以告诉你某种东西**一定不存在**或者**可能存在**。当布隆过滤器说，某种东西存在时，这种东西可能不存在；当布隆过滤器说，某种东西不存在时，那么这种东西一定不存在。

​			布隆过滤器相对于Set、Map 等数据结构来说，它可以更高效地插入和查询，并且占用空间更少，它也有缺点，就是判断某种东西是否存在时，可能会被误判。但是只要参数设置的合理，它的精确度也可以控制的相对精确，只会有小小的误判概率。

​			 那么从上方的描述中我们可以总结出来几个比较重要的点：

```
					1、布隆过滤器是一种数据结构
					2、布隆过滤器说他存在时有可能不存在，说他不存在时一定不存在
					3、它可以更高效地插入和查询，并且占用的空间少
```

​			那么我们的布隆过滤器可以用在哪些场景下进行使用呢？

​						例如，防止缓存击穿、爬虫Url去重，过滤黑名单请求，等等。

## 什么是BigKey（大Key）

​		Redis中的大key一直是重点需要优化的对象，Big Key不是指这个Key大，而是指相应的Key的Value比较大，Redis的多种数据类型都有可能出现BigKey。

​				String			字符串的值过长，几十m（兆），甚至上百m（兆）

​				Hash			 Hash中的元素存放过多，例如一个Hash中存放上万甚至更多个元素

​				Set、Zset	 存放元素过多，如果出现获取多个甚至get all也会出现各种问题

## BigKey会造成什么影响？

​		举个例子我们来进行说明，比如Redis中有一个字符串Key，这个字符串是20m，那么这个时候我们有50个请求过来访问，那么这个时候的网络带宽则会占用到20 * 50 = 1000，虽然有千兆网卡但是实际的网络带宽一般都不会到千兆例如实际速度为 1000 / 8  = 125m,这个时候差不多接近十倍的流量是特别夸张的，会直接打满网卡造成网络阻塞。

​		并且我们在删除的时候，如果是单节点直接进行DEL 操作，被操作的实例会被Block住，导致无法响应应用的请求，而这个Block的时间会随着key的变大而变长，那么对Redis的性能会有非常大的影响，集群情况下对节点也是非常大的影响。

## 如何查找BigKey？

- ​							1、使用Redis的原生命令 --bigkeys

```sh
# 进入redis的bin目录或者配置,执行命令
redis-cli --bigkeys -h 192.168.1.11 -p 20177  -n 6 -a topcom123  -i 0.1

-h hostIp地址
-p 端口号
-n 数据库
-a 密码
-i 扫描100个停止0.1秒
```

- ​							2、使用SCAN+debug获取所有Key的大小

```sh
# 首先测试一个key我们查看他的大小
set name 黄康111
debug object name
# 返回如下serializedlength就是我们的序列化长度
"Value at:0x7fea6880ee00 refcount:1 encoding:embstr serializedlength:7 lru:3439898 lru_seconds_idle:5"

# 然后我们使用scan
scan 0 match bigkang* count 4

# 返回如下
1) "7"
2) 1) "bigkang4"
   2) "bigkang3"
   3) "bigkang1"
   
# 再使用debug object统计查询相应的key
```

- ​							3、使用Redis命令bgsave，导出数据然后对数据查找BigKey

```sh
# 先对数据进行备份
bgsave

# 然后生成出来rdb文件我们使用工具进行分析

# 使用rdb_bigkeys进行分析
mkdir /home/gocode/
export GOPATH=/home/gocode/
cd GOROOT
git clone https://github.com/weiyanwei412/rdb_bigkeys.git
cd rdb_bigkeys
go get 
go build

# 执行bigkey分析命令，大于1024byte的key都会被查询出来到csv文件中
./rdb_bigkeys --bytes 1024 --file bigkeys.csv --sep 0 --sorted --threads 4 /home/redis/dump.rdb
```

## 如何避免优化BigKey？

​		对于我们的BigKey大部分都是由于业务设计的时候没有考虑到相应的数据量过于庞大的情况所造成的的，针对于样的BigKey大概有如下几种策略：

- ​				1、修改业务逻辑重新设计考虑其它方式，直接避免掉BigKey
- ​				2、对数据进行拆分，一个BigKey拆分为几个Key
- ​				3、优化设计，将数据量大幅度减少，或者避免全量取出，取出部分

## 如何删除BigKey？

​		对于String类型的字符串一般不会造成阻塞，直接释放，但是当我们删除hash、list、set、sorted set的BigKey的时候不能直接删除，否则会造成严重的性能影响，因为Redis是单线程的，处理hash等数据结构删除的时候会非常慢，所以删除这类数据结构我们需要一部分一部分的删除。

​		我们使用hscan以及其他scan，扫描出一部分元素，然后将这部分元素逐步删除，例如每次扫描100或者几百个元素删除，然后加上时间停顿的间隔，因为redis是单线程的，所以避免占用资源过高。

​		总结：

​					String类型可以直接删除

​					Hash等复杂结构使用对应的scan扫描部分，渐进式删除

## 了解过Redis跳跃表吗？

​		跳跃表是一种有序的数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。这么说，我们可能很难理解，我们可以先回忆一下链表。

​		我们知道链表的查询效率是特别低的，我们传统的链表如下

```sh
				1  --->   2   --->   3   --->   4   --->   5   --->   6   --->   7   --->   8
```

​		跳跃表每次跳跃节点数量为1的时候如下

```sh
L1			1        --->		     3         --->	       5         --->	       7   --->  	8
				1  --->   2   --->   3   --->   4   --->   5   --->   6   --->   7   --->   8
```

​		跳跃表每次跳跃节点数量为2的时候如下

```sh
L2			1                --->		        4              --->	             7
L1			1        --->		     3         --->	       5         --->	       7   --->  	8
				1  --->   2   --->   3   --->   4   --->   5   --->   6   --->   7   --->   8
```

​		简单的来说就是构建多级的跳跃索引，这样就能提升链表的一个查询效率

​		参考如下博客：https://www.cnblogs.com/hunternet/p/11248192.html

## 缓存与数据库双写一致问题如何解决？

​		例如我们对MySQL中的某项数据进行了修改，这个时候就有可能导致缓存和数据库的数据不一致的问题了，那么针对于这种问题我们有什么解决方案吗？

​		答案就是：

- ​					删除后更新

```sh
# 删除后更新就是先删除掉缓存，然后再去更新数据库
1、先删除缓存
2、更新数据库

# 该方案在线程A进行数据更新操作，线程B进行查询操作时，有可能出现下面的情况导致数据不一致
		线程A删除缓存
		线程B查询数据，发现缓存数据不存在
		线程B查询数据库，得到旧值，写入缓存
		线程A将新值更新到数据库
```

- ​					更新后删除

```sh
# 更新后删除就是先更新数据库，然后再去删除掉缓存
1、先更新数据库
2、删除缓存

# 当缓存失效时，线程B原子性被破坏时会出现不一致问题：
    缓存失效了
    线程B从数据库读取旧值
    线程A从数据库读取旧值
    线程B将新值更新到数据库
    线程B删除缓存
    线程A将旧值写入缓存
```

- ​					延时双删

```sh
# 延时双删从名字可以看出来需要删除两次，步骤如下
1、先删除缓存
2、更新数据库
3、更新完毕后，再延时删除一次缓存
```

- ​					异步更新缓存

```sh
# 异步更新缓存表示，我们修改了数据库，然后异步地把缓存更新，步骤如下
1、更新数据库数据
2、监听数据库更变
3、根据更新更新缓存
# 这种同步机制类似于MySQL的主从备份机制，可以结合使用阿里的canal对MySQL的binlog进行订阅。
```

## 你过往的工作经历中，是否出现过缓存集群事故，说说细并说说高可用的保障的方案


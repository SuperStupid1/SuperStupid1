

# 为什么要引入消息队列，引入理由是什么

​		主要原因是由于在高并发环境下，由于来不及同步处理，请求往往会发生堵塞，比如说，大量的insert，update之类的请求同时到达数据库，直接导致无数的行锁表锁，甚至最后请求会堆积过多，从而触发too many connections错误，以及对于一部分不是强一致性的操作，例如发送短信，发送邮件或者其他的可以异步执行，以及保持最终一致的数据我们都可以采用消息队列进行处理。

​		主要有如下用处：

- ​				应用解耦（通用功能）
- ​                异步操作
- ​                流量消峰（高访问量使用队列排队处理）
- ​                消息通知（短信，邮件等）

# 项目中你们是怎么使用消息队列的

​		主要用于消息数据处理，例如大量的爬虫数据，分析过滤入库操作，可以采用MQ方式进行消费，以及发送短信操作，发送邮件，以及生成图片，还有分布式消息通知，例如多节点发布订阅消息，进行处理，以及其他各种系统可能会出现重复的功能解耦。

# 主流消息队列都有哪些？

​		ActiveMQ

```properties
		# Apache ActiveMQ是Apache软件基金会所研发的开放源代码消息中间件；由于ActiveMQ是一个纯Java程序，因此只需要操作系统支持Java虚拟机，ActiveMQ便可执行。
		
		特点: 
				单机吞吐量: 万级
				  消息延迟: 毫秒级
		总结: 老牌MQ，采用纯JAVA编写，性能一般，中规中矩
```

​		Kafka

```properties
		# Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。 
		
		特点: 
				单机吞吐量: 十万级
				  消息延迟: 毫秒级
		总结: 吞吐量高，适合大量数据处理，但是可能会丢失消息，以及重复消费
```

​		RabbitMQ

```properties
		# RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而集群和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。
		
		特点: 
				单机吞吐量: 万级
				  消息延迟: 微秒级
		总结: 性能高，延迟低，但是采用Erlang编写，不方便集群拓展，功能强大，但吞吐量一般
```

​		RocketMQ

```properties
		# RocketMQ的最佳实践，包括生产者、消费者、Broker以及NameServer的最佳实践，客户端的配置方式以及JVM和linux的最佳参数配置。采用Java开发。
		
		特点: 
				单机吞吐量: 数万级
				  消息延迟: 毫秒级
		总结: 延迟一般，吞吐量较高，并且对数据的一致性保持较高，功能强大，是目前性能较高的MQ
```

# Kafka

## 消息丢失如何解决

​		我们在发送消息的时候可能会出现消息丢失的情况，例如我们发送消息给某一个Topic分区，这个时候发送到了Leader上，但是Leader没有来得及同步数据给副本，自己就挂掉了，这个时候我们的消息就会丢失，由于副本升级为Leader但是他并没有从原来的Leader同步到数据，所以导致了数据丢失。

​		针对与这种情况，Kafka的生产者给我们提供了配置，我们可以通过配置**acks**属性来设置，对应的防止消息丢失的情况。

​		**acks**设置一共有三个属性

```properties
		#acks = 0 
       如果设置为零，则生产者将不等待来自的任何确认完全是服务器。记录将立即添加到套接字缓冲区中并视为已发送。无法保证。表示服务器在这种情况下已收到记录，也就是我们的生产者像Broker代理发送消息，我们不保证Broker收到了消息，如果我们生产者发送消息到Socket缓冲区，我们就认为他发送成功了，会导致消息丢失，retries配置将不会生效（因为客户端通常不会知道任何故障）。为每个记录提供的偏移量将是始终设置为-1。
		# acks = 1 (可能消息丢失)
        这将意味着领导者会将记录写入其本地日志，但会做出响应而无需等待所有关注者的完全确认。在这种情况下，领导者应在之后立即失败确认记录，但是在关注者复制该记录之前该记录将丢失，我们向Broker发送消息，至少写入Leader，然后Leader将数据同步到1个副本集中，我们就认为他已经是属于发送成功了。
		# acks = all（消息不丢失）
        这意味着领导者将等待完整的同步副本到确认记录。这保证只要至少一个同步副本，记录也不会丢失仍然有效。这是最强大的保证。它等于acks=-1的设置，表示我们发送消息到Broker，然后分区Leader写入，写入完成后必须将数据再同步给所有的副本，同步完成后才数据发送成功。
    
    # 发送失败会导致生产者循环发送消息，直到发送成功为止，可以通过其他配置修改
```

## 消息重复如何解决

​		同样是在生产者，为了防止我们发送消息的时候由于网络抖动，或者其他的的原因，导致处理消息丢失或者其他情况时所引起的消息生产发送重复，引起的数据混乱，那么针对这种情况我们可以通过开启Kafka的幂等性来防止消息重复，通过属性**enable.idempotence**

```properties
		# 将幂等性开启，幂等性会在发送消息的时候附带上一个序列ID，如果出现了消息重试等操作，根据这个序列ID我们可以防止消息的重复
```

## 聊一聊Kafka的ISR

​		afka在启动的时候会开启两个与ISR相关的定时任务，名称分别为“isr-expiration"和”isr-change-propagation".。isr-expiration任务会周期性的检测每个分区是否需要缩减其ISR集合。这个周期和“[replica.lag.time.max.ms](http://replica.lag.time.max.ms/)”参数有关。大小是这个参数一半。默认值为5000ms，当检测到ISR中有是失效的副本的时候，就会缩减ISR集合。如果某个分区的ISR集合发生变更， 则会将变更后的数据记录到ZooKerper对应/brokers/topics/[topic]/partitions/[partition]/state节点中。

​		结合上上面的消息丢失的ack机制，这条数据才会被Commit，例如我们从partition的leader进行写入，他会将数据同步到follwer中，如果说在写入leader的时候，写完了leader这个时候还没有同步到follwer那么则会出现消息丢失的情况。

​		所以在Kafka生产者写的时候我们会向follwer也进行写入，但是follwer也是有可能出现问题的，所以为了会出现数据一致性的问题，如果follwer出现了问题就对follwer进行更变，及时剔除无效的follwer。



# RabbitMQ

## 如何高可用？



​		镜像集群模式：<br> 		   这种模式就是所谓的ribbtimq的高可用模式，跟普通的模式不一样的是，你创建的queue无论是元数据还是queue消息都会在多个实例上，然后你发送消息到queue的时候，都会自动把消息发送到多个实例的queue里进行同步<br> <br>			怎么开启？<br>			有管理平台，在后台增加一个策略



## 如何保证消息不重复消费？



​		最好的方法写到redis里，反正每次都是set，天然幂等



## 如何保证消息发送可靠性？



​		1：生产者把数据弄丢了：<br>

  			  在生成者这里开启confirm模式。他会每次写的消息都会分配一个唯一的id，如果写入ribbitMQ，会回传一个ack消息。如果ribbitmq没有处理这个消息，会回调一个nack接口，告诉你这个消息接收失败，你可以重试<br>

​		2：rabbitMQ弄丢消息？<br>

   		 	开启rabbitMQ的持久化。创建queue的时候就持久化。<br> 			   发送消息的时候，将deliveryMode设置2.如果是ribbitmq挂了，从磁盘中恢复queue的时候，也会恢复数据<br>

​		3：消费者弄丢了数据<br>

​	  			ribbitmq提供了完整的ack机制，简单来说，关了raibbitmq，自动ack。在自己代码里确保处理的时候，调用api在程序ack一把。...



## 如何保证消息的有序性？



​		拆成多个queue，每一个queue对应着一个consumer。



## 如何保证数据一致性？



​		**⽣产者确认机制：**消息持久化后异步回调通知⽣产者，保证消息已经发出去；

​		**消息持久化：**设置消息持久化；

​		**消费者确认机制：**消费者成功消费消息之后，⼿动确认，保证消息已经消费。



## 设置过期时间导致消息丢失，如何解决？

​		首先线上是不允许设置过期时间的，即不会存在这种问题。

​		如果真的设置了过期时间，需要怎么做？

​		这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。

​		假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次。

## MQ集群怎么保证数据的串行处理？

​		mq本身的集群可以保证串行的或者镜像模式更好. 如果调用mq的应用程序本身是集群部署的，则只能保证基本串行处理，另外如果需要一个个地处理数据，需要加上分布式锁。

## 死信队列？



# 统一问题



## 如何设计一个消息队列？



​		首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？

​		其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。

​		其次你考虑一下你的 mq 的可用性啊？能不能支持数据 0 丢失啊？



## 百万级别消息积压几小时，如何解决？

一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：

​	1）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉<br>

​	2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量<br>	3）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue<br>	4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据<br>	5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据<br>	6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息<br>




# **数据库相关**

### MyISAM和InnoDB的区别

​			1、事务

​						InnoDB支持事务，MyISAM不支持事务

​			2、备份

​						InnoDB支持在线热备份					

​			3、崩溃恢复

​						MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。

​			4、并发

​						MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。

​			5、外键

​						InnoDB支持外键，而MyISAM不支持

​			6、全文索引

​						InnoDB不支持全文索引，而MyISAM支持

​			7、其他特性

​						MyISAM 支持全文索引，地理空间索引。

​			InnoDB的特点：

​						插入缓冲，二次写，自适应哈希索引，预读

### MySQL的日志有哪些？

​					1、错误日志

​								记录出错信息，也记录一些警告信息或者正确的信息

​					2、查询日志

​								记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行

​					3、慢查询日志

​								设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中

​					4、二级制日志

​								记录对数据库执行更改的所有操作

​					5、中继日志

​					 			中继日志也是二进制日志，用来给slave 库恢复

​					6、事务日志(重做日志（redo log）)

​								作用是确保事务的持久性，防止在发生故障的时间点，尚有脏页未写入磁盘。

​								在重启 MySQL 服务的时候，根据 redo log 进行重做，

​								从而达到事务的持久性这一特性。		

​					7、回滚日志

​								保存了事务发生之前的数据的一个版本，可以用于回滚，

​								同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。





### 常见的数据库优化手段索引的优缺点

​		常见的优化手段有：

​			1、在编写SQL语句时不使用*，而是使用字段名，哪怕每一个字段名都写上去，

​			2、添加索引，使查询效率变高，尤其是在where条件中的字段

​			3、尽量不要在列上进行运算（函数操作和表达式操作）否则索引失效

​			4、不使用not in  和 <>   以及！=否则索引失效

​			5、在使用like语句时不要以%开头否则索引失效

​			6、多表联查时多使用小表作为驱动表，因为（驱动表必须全表查询）

​			

### 什么字段上建立索引数据库

​			1、在作为where条件出现较多的表



​			2、尽量建立索引时将顺序排好的字段（否则查询时中间一个字段没有用上后面的都用不上）

​			

​			3、尽量选择一些和其他表有关联的字段，如订单表的用户字段

### 你们数据库的高可用架构是怎么样的？

​		一般来说数据库的备份我们采用主从复制（注：单纯的主从并不是高性能或者高可用的），而为了提高性能我们在主从之后会使用Mycat进行读写分离，但是他也只是做到了高性能并没有做到高可用，那么如何做到高可用呢，就是我们使用KeepAlive进行虚拟化ip，如果使用简单的高可用加高性能那么我们就直接通过KeepAlive，去连接主机然后再进行访问，如果主机挂掉了就直接使用丛机进行读写，等恢复主机之后将主机变为丛机，读取丛机的数据，或者恢复后同步数据，再使用指向主机，下面分别是高可用和一个高性能可用的架构图

​		![](img/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8.png)

![](img/MySQL%E4%B8%BB%E4%BB%8E%E9%AB%98%E5%8F%AF%E7%94%A8.png)

### 如何保证数据库主从一致性？

​		**方案一：忽略**

​				任何脱离业务的架构设计都是耍流氓，绝大部分业务，例如：百度搜索，淘宝订单，QQ消息，58帖子都允许短时间不一致。如果业务能接受，最推崇此法。别把系统架构搞得太复杂。

​		**方案二：选择性主读**

​				将哪个库，哪个表，哪个主键三个信息拼装一个key设置到cache里，这条记录的超时时间，设置为“主从同步时延” ，画外音：key的格式为“db:table:PK”，假设主从延时为1s，这个key的cache超时时间也为1s。 这是要读哪个库，哪个表，哪个主键的数据呢，也将这三个信息拼装一个key，到cache里去查询， 在cache里记录哪些记录发生过写请求，来路由读主还是读从 

### 为什么mongodb的索引用了B树，而mysql用B+树？

​		我们首先来看一下B树的结构

​			B树的特点就是每一层的节点数据非常多，而层数比较少，目的就是为了减少IO次数

​			B树的每个节点都是有data域的（指针），这无疑增大了节点大小

​		再来看一下B+树的结构

​			B+树的特点就是，B+树所有的Data域在叶子节点 ，非叶子节点存储索引数据

​			B+树只要遍历叶子节点就可以实现整棵树的遍历

### 用mysql过程中，有遇到什么问题么？

### 你们生产用的是哪种事务隔离级别，为什么？

### 什么情况下会造成索引失效？

​		1、使用or关键字，如果条件中有or，即使其中有条件带索引也不会使用 

​					注意：使用or，又想索引生效，只能将or条件中的每个列都加上索引 

​		2、索引顺序不一致，例如索引为（name，age，email），而查询时（name，email，age）则会造成只有name生效，其他两个字段用不到索引

​					注意：尽量避免索引顺序不一致，如果实在避免不了，在设计时就应先考虑顺序

​		3、以like %开头的关键字，如果以like %name查询，会使索引失效

​					注意：尽量使用 like name%这种，因为%号在后面还是能实用索引

​		4、如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不会使用索引 

​					注意：字符串类型列一定要使用引号（虽然情况很少）

​		5、 where语句中使用 <>和 !=   还有not  in，如果使用了不等于那么他会全表扫描

​					注意：尽量不要使用不等于或者not

​		6、 where语句中对字段表达式操作，例如where age * 2 = 100

​					注意：不要使用表达式，尽量使用age = 50

### 并发事务修改会造成哪些影响

会造成的常见影响有：

​										更新丢失：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了其他事务所做的更新。

​												幻读：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。

​												脏读：一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”。

​									不可重复读：一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！这种现象叫做“不可重复读”。

# 你所遇到的Mysql事故

### rancher引起

在使用rancher的时候，发现许多连接的错误，随之mysql就自动关闭了，这是什么原因呢

```
2019-08-14T11:18:30.558570Z 4 [Note] Aborted connection 4 to db: 'cattle' user: 'cattle' host: '10.18.16.99' (Got an error reading communication packets)
2019-08-14T11:18:30.558705Z 6 [Note] Aborted connection 6 to db: 'cattle' user: 'cattle' host: '10.18.16.99' (Got an error reading communication packets)
```

我们可以看到非常多的连接请求，然后读取数据报出错，那应该是连接的问题了，那么到底什么原因会引起mysql连接报错呢，当然就是连接数量太多所引起的，这个问题在rancher中能够体现，我们使用rancher监控服务器，然后重启了mysql，rancher就不停请求mysql，只要我们一重启mysql就直接崩溃了，所以我们需要

```
方法一：修改配置文件（永久生效）。
在/etc/my.conf文件加入 max_connections=2000 ，然后重启MySQL服务即可.

方法二：命令行修改（临时生效）
命令行登录MySQL后。设置新的MySQL最大连接数为2000：
MySQL> set global max_connections=2000;
```

然后还是发现有问题连接不上，是因为我们发送了太多的连接请求，超过了mysql的异常连接数量导致ip被mysql拒绝，这个时候我们需要刷新一下缓存

```
flush host
```

但是究竟是什么导致链接数上升，前端开始重建链接，由于当时的前端日志没有及时分析出来，故我们就不得而知了。但是有3个怀疑点：

1、由于mysql版本是5.5.12，所以可能遇到了max_connections的bug，可以见这个blog（http://www.cnblogs.com/billyxp/p/3408335.html），这种情况下，前端日志应该有非常多的too many connection是的报错。

2、短时间内有大量的大包传输，导致超过max_allow_packet的限制，导致断开连接。这个设置在server和client上都有，需要同步配置。同时前端应该报Got a packet bigger than ‘max_allowed__packet’ bytes这个报错。

3、超过max_connect_error的限制，导致某一个ip出现问题，不停的重试。（这个可能是最不可能，首先默认数值非常大，其次单个ip不应该出现这么大的影响。max_connect_error代表某一个ip连续失败超过n之后，server会拒绝这个ip的请求，只有flush host cache才可以解封。）

异常